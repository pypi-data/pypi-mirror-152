# coding: utf-8

"""
    Deci Platform API

    Train, deploy, optimize and serve your models using Deci's platform, In your cloud or on premise.  # noqa: E501

    The version of the OpenAPI document: 1.19.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from deci_client.deci_api.configuration import Configuration


class TrainExperimentHyperParameters(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'loss': 'str',
        'criterion_params': 'dict(str, float)',
        'optimizer': 'str',
        'optimizer_params': 'object',
        'max_epochs': 'int',
        'initial_lr': 'float',
        'lr_mode': 'str',
        'lr_updates': 'list[object]',
        'lr_decay_factor': 'float',
        'lr_warmup_epochs': 'int',
        'mixed_precision': 'bool'
    }

    attribute_map = {
        'loss': 'loss',
        'criterion_params': 'criterionParams',
        'optimizer': 'optimizer',
        'optimizer_params': 'optimizerParams',
        'max_epochs': 'maxEpochs',
        'initial_lr': 'initialLr',
        'lr_mode': 'lrMode',
        'lr_updates': 'lrUpdates',
        'lr_decay_factor': 'lrDecayFactor',
        'lr_warmup_epochs': 'lrWarmupEpochs',
        'mixed_precision': 'mixedPrecision'
    }

    def __init__(self, loss=None, criterion_params=None, optimizer=None, optimizer_params=None, max_epochs=None, initial_lr=None, lr_mode='step', lr_updates=[], lr_decay_factor=None, lr_warmup_epochs=None, mixed_precision=False, local_vars_configuration=None):  # noqa: E501
        """TrainExperimentHyperParameters - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._loss = None
        self._criterion_params = None
        self._optimizer = None
        self._optimizer_params = None
        self._max_epochs = None
        self._initial_lr = None
        self._lr_mode = None
        self._lr_updates = None
        self._lr_decay_factor = None
        self._lr_warmup_epochs = None
        self._mixed_precision = None
        self.discriminator = None

        self.loss = loss
        self.criterion_params = criterion_params
        self.optimizer = optimizer
        self.optimizer_params = optimizer_params
        self.max_epochs = max_epochs
        self.initial_lr = initial_lr
        if lr_mode is not None:
            self.lr_mode = lr_mode
        if lr_updates is not None:
            self.lr_updates = lr_updates
        if lr_decay_factor is not None:
            self.lr_decay_factor = lr_decay_factor
        if lr_warmup_epochs is not None:
            self.lr_warmup_epochs = lr_warmup_epochs
        if mixed_precision is not None:
            self.mixed_precision = mixed_precision

    @property
    def loss(self):
        """Gets the loss of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The loss of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: str
        """
        return self._loss

    @loss.setter
    def loss(self, loss):
        """Sets the loss of this TrainExperimentHyperParameters.


        :param loss: The loss of this TrainExperimentHyperParameters.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and loss is None:  # noqa: E501
            raise ValueError("Invalid value for `loss`, must not be `None`")  # noqa: E501

        self._loss = loss

    @property
    def criterion_params(self):
        """Gets the criterion_params of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The criterion_params of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: dict(str, float)
        """
        return self._criterion_params

    @criterion_params.setter
    def criterion_params(self, criterion_params):
        """Sets the criterion_params of this TrainExperimentHyperParameters.


        :param criterion_params: The criterion_params of this TrainExperimentHyperParameters.  # noqa: E501
        :type: dict(str, float)
        """
        if self.local_vars_configuration.client_side_validation and criterion_params is None:  # noqa: E501
            raise ValueError("Invalid value for `criterion_params`, must not be `None`")  # noqa: E501

        self._criterion_params = criterion_params

    @property
    def optimizer(self):
        """Gets the optimizer of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The optimizer of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: str
        """
        return self._optimizer

    @optimizer.setter
    def optimizer(self, optimizer):
        """Sets the optimizer of this TrainExperimentHyperParameters.


        :param optimizer: The optimizer of this TrainExperimentHyperParameters.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and optimizer is None:  # noqa: E501
            raise ValueError("Invalid value for `optimizer`, must not be `None`")  # noqa: E501

        self._optimizer = optimizer

    @property
    def optimizer_params(self):
        """Gets the optimizer_params of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The optimizer_params of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: object
        """
        return self._optimizer_params

    @optimizer_params.setter
    def optimizer_params(self, optimizer_params):
        """Sets the optimizer_params of this TrainExperimentHyperParameters.


        :param optimizer_params: The optimizer_params of this TrainExperimentHyperParameters.  # noqa: E501
        :type: object
        """
        if self.local_vars_configuration.client_side_validation and optimizer_params is None:  # noqa: E501
            raise ValueError("Invalid value for `optimizer_params`, must not be `None`")  # noqa: E501

        self._optimizer_params = optimizer_params

    @property
    def max_epochs(self):
        """Gets the max_epochs of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The max_epochs of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: int
        """
        return self._max_epochs

    @max_epochs.setter
    def max_epochs(self, max_epochs):
        """Sets the max_epochs of this TrainExperimentHyperParameters.


        :param max_epochs: The max_epochs of this TrainExperimentHyperParameters.  # noqa: E501
        :type: int
        """
        if self.local_vars_configuration.client_side_validation and max_epochs is None:  # noqa: E501
            raise ValueError("Invalid value for `max_epochs`, must not be `None`")  # noqa: E501

        self._max_epochs = max_epochs

    @property
    def initial_lr(self):
        """Gets the initial_lr of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The initial_lr of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: float
        """
        return self._initial_lr

    @initial_lr.setter
    def initial_lr(self, initial_lr):
        """Sets the initial_lr of this TrainExperimentHyperParameters.


        :param initial_lr: The initial_lr of this TrainExperimentHyperParameters.  # noqa: E501
        :type: float
        """
        if self.local_vars_configuration.client_side_validation and initial_lr is None:  # noqa: E501
            raise ValueError("Invalid value for `initial_lr`, must not be `None`")  # noqa: E501

        self._initial_lr = initial_lr

    @property
    def lr_mode(self):
        """Gets the lr_mode of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The lr_mode of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: str
        """
        return self._lr_mode

    @lr_mode.setter
    def lr_mode(self, lr_mode):
        """Sets the lr_mode of this TrainExperimentHyperParameters.


        :param lr_mode: The lr_mode of this TrainExperimentHyperParameters.  # noqa: E501
        :type: str
        """

        self._lr_mode = lr_mode

    @property
    def lr_updates(self):
        """Gets the lr_updates of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The lr_updates of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: list[object]
        """
        return self._lr_updates

    @lr_updates.setter
    def lr_updates(self, lr_updates):
        """Sets the lr_updates of this TrainExperimentHyperParameters.


        :param lr_updates: The lr_updates of this TrainExperimentHyperParameters.  # noqa: E501
        :type: list[object]
        """

        self._lr_updates = lr_updates

    @property
    def lr_decay_factor(self):
        """Gets the lr_decay_factor of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The lr_decay_factor of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: float
        """
        return self._lr_decay_factor

    @lr_decay_factor.setter
    def lr_decay_factor(self, lr_decay_factor):
        """Sets the lr_decay_factor of this TrainExperimentHyperParameters.


        :param lr_decay_factor: The lr_decay_factor of this TrainExperimentHyperParameters.  # noqa: E501
        :type: float
        """

        self._lr_decay_factor = lr_decay_factor

    @property
    def lr_warmup_epochs(self):
        """Gets the lr_warmup_epochs of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The lr_warmup_epochs of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: int
        """
        return self._lr_warmup_epochs

    @lr_warmup_epochs.setter
    def lr_warmup_epochs(self, lr_warmup_epochs):
        """Sets the lr_warmup_epochs of this TrainExperimentHyperParameters.


        :param lr_warmup_epochs: The lr_warmup_epochs of this TrainExperimentHyperParameters.  # noqa: E501
        :type: int
        """

        self._lr_warmup_epochs = lr_warmup_epochs

    @property
    def mixed_precision(self):
        """Gets the mixed_precision of this TrainExperimentHyperParameters.  # noqa: E501


        :return: The mixed_precision of this TrainExperimentHyperParameters.  # noqa: E501
        :rtype: bool
        """
        return self._mixed_precision

    @mixed_precision.setter
    def mixed_precision(self, mixed_precision):
        """Sets the mixed_precision of this TrainExperimentHyperParameters.


        :param mixed_precision: The mixed_precision of this TrainExperimentHyperParameters.  # noqa: E501
        :type: bool
        """

        self._mixed_precision = mixed_precision

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, TrainExperimentHyperParameters):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, TrainExperimentHyperParameters):
            return True

        return self.to_dict() != other.to_dict()
