Metadata-Version: 2.1
Name: exfill
Version: 0.1.17
Summary: A small app to grab job postings from online job boards
Home-page: https://github.com/jay-law/job-scraper
Author: jay-law
Author-email: jay-law@users.noreply.github.com
Requires-Python: >=3.8,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Requires-Dist: black (>=22.3.0,<23.0.0)
Requires-Dist: bs4 (>=0.0.1,<0.0.2)
Requires-Dist: pandas (>=1.4.2,<2.0.0)
Requires-Dist: selenium (>=4.1.5,<5.0.0)
Requires-Dist: setuptools-scm (>=6.4.2,<7.0.0)
Project-URL: Documentation, https://github.com/jay-law/job-scraper
Project-URL: Repository, https://github.com/jay-law/job-scraper
Description-Content-Type: text/markdown

# Introduction

Job boards (like LinkedIn) can be a good source for finding job openings.  Unfortunately the search results cannot always be filtered to a usable degree.  This application lets users scrape and parse jobs with more flexability provided by the default search.

Currently only LinkedIn is supported.

# Project Structure

Directories:
- `src/exfill/parsers` - Contains parser(s)
- `src/exfill/scrapers` - Contains scraper(s)
- `src/exfill/support` 
    - Contains `geckodriver` driver for FireFox which is used by Selenium
    - Download the latest driver from the [Mozilla GeckoDriver repo in GitHub](https://github.com/mozilla/geckodriver)
- `data/html` 
    - Not in source control
    - Contains HTML elements for a specific job posting
    - Populated by a scraper
- `data/csv` 
    - Not in source control
    - Contains parsed information in a csv table
    - Populated by a parser
    - Also contains an error table
- `logs` 
    - Not in source control
    - Contains logs created during execution

## `creds.json` File

Syntax should be as follows:

```json
{
    "linkedin": {
        "username": "jay-law@gmail.com",
        "password": "password1"
    }
}
```

# Usage

There are two phase.  First is scraping the postings.  Second is parsing the scraped information.  Therefore the scraping phase must occur before the parsing phase.

## Use as Code

```bash
# Install with git
$ git clone git@github.com:jay-law/job-scraper.git

# Create and populate creds.json

# Execute - Scrape linkedin
$ python3 src/exfill/extractor.py linkedin scrape

# Execute - Parse linkedin
$ python3 src/exfill/extractor.py linkedin parse
```

## Use as Module

```bash
# Install
$ python3 -m pip install --upgrade exfill

# Execute - Scrape linkedin
$ python3 -m exfill.extractor linkedin scrape

# Execute - Parse linkedin
$ python3 -m exfill.extractor linkedin parse
```

# Roadmap

* [ ] Write unit tests
* [ ] Improve secret handling
* [x] Add packaging
* [x] Move paths to config file
* [x] Move keyword logic
* [x] Set/include default config.ini for users installing with PIP
* [x] Add CICD
* [x] Automate versioning
* [x] Add formatter (black module)
* [x] Add static type checking (mypy module)
* [x] Add import sorter (isort module)
* [x] Add linter (flake8 module)
* [x] Update string interpolation from %f to f-string
* [x] Replace sys.exit calls with exceptions
* [x] Update how the config object is accessed
* [x] Migrate to `poetry` for virtual env, building, and publishing
