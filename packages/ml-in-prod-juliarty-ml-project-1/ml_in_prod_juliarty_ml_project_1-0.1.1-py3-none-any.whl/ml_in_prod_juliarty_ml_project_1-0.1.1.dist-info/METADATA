Metadata-Version: 2.1
Name: ml-in-prod-juliarty-ml-project-1
Version: 0.1.1
Summary: That is a homework project
Home-page: https://github.com/made-ml-in-prod-2022/juliarty
Author: Juliarty
Author-email: sirrzk.09@yandex.ru
Project-URL: Bug Reports, https://github.com/made-ml-in-prod-2022/juliarty/issues
Project-URL: Source, https://github.com/made-ml-in-prod-2022/juliarty/
Keywords: homework ml in prod
Requires-Python: >=3.8, <4
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyyaml (==6.0)
Requires-Dist: marshmallow-dataclass (==8.5.8)
Requires-Dist: pandas (~=1.4.2)
Requires-Dist: scikit-learn (~=1.0.2)
Requires-Dist: numpy (~=1.22.3)
Requires-Dist: omegaconf (~=2.1.2)
Requires-Dist: hydra-core (==1.1.2)
Requires-Dist: hydra-colorlog (==1.1.0)
Requires-Dist: pytest (~=7.1.2)
Requires-Dist: gdown (==4.4.0)



Download dataset:
   1. Use Kaggle public API (https://www.kaggle.com/docs/api). 
   2. Type the following commands:
      - cd ml_project/data/raw
      - kaggle datasets download -d cherngs/heart-disease-cleveland-uci
      - unzip heart-disease-cleveland-uci.zip 
      - rm heart-disease-cleveland-uci.zip


RUN train with default config:
```
   cd ml_project
   python -m src.pipelines.train_pipeline
```

RUN train with overrode config (all pipelines' configs are in configs/train_pipelines folder):
```
   cd ml_project
   python -m src.pipelines.train_pipeline +train_pipelines=forest_train_pipeline
```

Run predict with default config:
```
    cd ml_project
    python -m src.pipelines.predict_pipeline
```
RUN tests:
```
   cd ml_project
   pytest
```

Архитектурные решения:
- Проект ml-project представляет собой пакет Python. Структура пакета (заимствована стуктура cookiecutter-data-science):
```
├── __init__.py
├── README.md         
├── data
│   └── raw            <- Исходный датасет
│
├── notebooks          <- Результаты анализа данных и прототипы.
│   └── EDA.ipynb
│
├── configs            <- Конфигурации проекта в формате .yaml
│   ├── train_pipelines      <- Измененные default конфигурации train пайплайнов
│   ├── features
│   ├── model
│   ├── preprocessing
│   ├── split
│   ├── default_train_pipeline.yaml
│   └── default_predict_pipeline.yaml
│   
├── requirements.txt  
│
├── outputs            <- Все артефакты создаваемые пайплайнами (модели, метрики, используемые конфигурационные файлы).  
│   ├── train
│   └── inference
└── src                <- Исходный код.
    ├── __init__.py    
    ├── tests
    └── pipelines
        ├── __init__.py
        ├── train_pipeline.py   
        ├── predict_pipeline.py 
        │
        ├── data           <- Модули, содержащие код для предобработки данных.
        │   ├── __init__.py
        │   ├── features_params.py   <- Класс для конфигурации (Выделяемые из датасета признаки).
        │   ├── split_params.py      <- Класс для конфигурации (Размеры тренировочного и тестого датасетов).
        │   └── make_dataset.py      <- Создание датафрейма, разбиение на тренировочные и тестовые данные.
        │
        ├── preprocessing       <-  Содержит трансформеры для подготовки данных.
        │   ├── __init__.py
        │   ├── preprocessing_params.py     <- Класс для конфигурации (Параметры трансформера).
        │   └── transformers.py
        │
        └── models      <- Обучение, использовние и конфигурирование модели.
            ├── __init__.py
            ├── model_params.py   <- Класс для конфигурации (Параметры модели).
            ├── predict_model.py  
            └── train_model.py    
```
- Для тренировки модели и использования обученной модели созданы соответствующие пайплайны (src/pipelines).
- Проект имеет модульную структуру (за каждую часть пайплайна отвечает определенный пакет).
- Для конфигурирования использована hydra.
- Данные скачиваются с Google Drive.
- Артефакты сохраняются в папке outputs/train, outputs/inference.
- Для тестирования пайплайнов генерируются данные приближенные к реальным: 
  - категориальные
  - числовые (с дискретными и непрерывными распределенями) в пределах минимальных и максимальных значений

1. В описании к пулл реквесту описаны основные "архитектурные" и тактические решения. (1/1)
2. В пулл-реквесте проведена самооценка (1/1)
3. Выполнено EDA и прототипирование. Нет скрипта (1/2)
4. Написана функция/класс для тренировки модели, вызов оформлен как утилита командной строки, записана в readme инструкция по запуску (3/3)
5. Написана функция/класс predict (вызов оформлен как утилита командной строки), которая примет на вход артефакт/ы от обучения, 
   тестовую выборку (без меток) и запишет предикт по заданному пути, инструкция по вызову записана в readme (3/3)
6. Проект имеет модульную структуру. Описание структуры проекта в README.md (2/2)
7. Использованы логгеры (2/2)
   - Используется модуль logging в основных модулях (пайплайны, обучение, получение датасета).
   - Настройки модуля - измененнные настройки логгера hydra (вывод в файл и в консоль).
   - Логи подсвечиваются в консоли.
8. Написаны тесты на отдельные модули и на прогон обучения и predict. (3/3)
   - Для всех модулей и пайплайнов есть тесты. (framework pytest)
   - В CI отображается отчёт о покрытии (общее покрытие строк 93 %). 
9. Для тестов генерируются синтетические данные, приближенные к реальным. (2/2)
   - Данные генерируются дискретные (категориальные признаки, 'age' и т.д.) и непрерывные с равномерным распределением.
   - Все данные генерируются в пределах их минимальных и максимыльных значений.
   - Используются для тестирования как train, так и predict пайплайнов.
10. Обучение модели конфигурируется с помощью конфигов yaml. (3/3) 
    Есть две конфигурации (отличаются модели, признаки и параметры разбиения на train, test):
    - configs/default_train_pipeline.yaml
    - configs/pipelines/forest_train_pipeline.yaml
11. Используются датаклассы для сущностей из конфига, а не голые dict (2/2)
    - Все датакслассы конфигов находятся в директориях с соответствующими модулями.
    - Имена классов модулей содержащих датаклассы конфигов с суффиксом '_params'.
12. Напишите кастомный трансформер и протестируйте его (3/3)
    - Реализовано два кастомных трансформера (IdentityTransformer, OneHotTransformer)
    - OneHotTransformer осуществляет one-hot кодирование категориальных признаков 
      и рескейлинг числовых признаков.
    - Реализованы тесты на случайном датасете.
13. В проекте зафиксированы все зависимости (1/1)
14. Настроен CI для прогона тестов, линтера на основе github actions (3/3).

Дополнительные баллы:
1. Используется hydra для конфигурирования (3 балла)
2. Mlflow (Не используется: 0 баллов)
