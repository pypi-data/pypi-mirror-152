// @generated by tools/codegen/gen.py from DispatchKeyFunctions.h

// NB: The implementing C++ file is RegisterDispatchKey.cpp

// TODO: tighten this include
#include <ATen/Functions.h>

namespace at {
namespace dml {

TORCH_API Tensor abs(const Tensor & self);
TORCH_API Tensor & abs_(Tensor & self);
TORCH_API Tensor & abs_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & abs_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor sgn(const Tensor & self);
TORCH_API Tensor & sgn_(Tensor & self);
TORCH_API Tensor & sgn_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & sgn_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor & add_out(Tensor & out, const Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor & add_outf(const Tensor & self, const Tensor & other, Scalar alpha, Tensor & out);
TORCH_API Tensor add(const Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor & add_(Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor add(const Tensor & self, Scalar other, Scalar alpha=1);
TORCH_API Tensor & add_(Tensor & self, Scalar other, Scalar alpha=1);
TORCH_API Tensor all(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor & all_out(Tensor & out, const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor & all_outf(const Tensor & self, int64_t dim, bool keepdim, Tensor & out);
TORCH_API Tensor any(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor & any_out(Tensor & out, const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor & any_outf(const Tensor & self, int64_t dim, bool keepdim, Tensor & out);
TORCH_API Tensor & arange_out(Tensor & out, Scalar start, Scalar end, Scalar step=1);
TORCH_API Tensor & arange_outf(Scalar start, Scalar end, Scalar step, Tensor & out);
TORCH_API Tensor as_strided(const Tensor & self, IntArrayRef size, IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt);
TORCH_API Tensor & as_strided_(Tensor & self, IntArrayRef size, IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt);
TORCH_API Tensor atan(const Tensor & self);
TORCH_API Tensor & atan_(Tensor & self);
TORCH_API Tensor & atan_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & atan_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor bernoulli(const Tensor & self, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & bernoulli_out(Tensor & out, const Tensor & self, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & bernoulli_outf(const Tensor & self, c10::optional<Generator> generator, Tensor & out);
TORCH_API Tensor & bernoulli_(Tensor & self, const Tensor & p, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & bernoulli_(Tensor & self, double p=0.5, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor binary_cross_entropy_with_logits(const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight={}, const c10::optional<Tensor> & pos_weight={}, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor logical_not(const Tensor & self);
TORCH_API Tensor & logical_not_(Tensor & self);
TORCH_API Tensor & logical_not_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & logical_not_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor logical_xor(const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_xor_(Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_xor_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_xor_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor logical_and(const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_and_(Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_and_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_and_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor logical_or(const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_or_(Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_or_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & logical_or_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor ceil(const Tensor & self);
TORCH_API Tensor & ceil_(Tensor & self);
TORCH_API Tensor & ceil_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & ceil_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor clamp(const Tensor & self, c10::optional<Scalar> min=c10::nullopt, c10::optional<Scalar> max=c10::nullopt);
TORCH_API Tensor & clamp_out(Tensor & out, const Tensor & self, c10::optional<Scalar> min=c10::nullopt, c10::optional<Scalar> max=c10::nullopt);
TORCH_API Tensor & clamp_outf(const Tensor & self, c10::optional<Scalar> min, c10::optional<Scalar> max, Tensor & out);
TORCH_API Tensor & clamp_max_out(Tensor & out, const Tensor & self, Scalar max);
TORCH_API Tensor & clamp_max_outf(const Tensor & self, Scalar max, Tensor & out);
TORCH_API Tensor & clamp_min_out(Tensor & out, const Tensor & self, Scalar min);
TORCH_API Tensor & clamp_min_outf(const Tensor & self, Scalar min, Tensor & out);
TORCH_API Tensor dml_convolution(const Tensor & input, const Tensor & weight, const c10::optional<Tensor> & bias, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool transposed, IntArrayRef output_padding, int64_t groups);
TORCH_API std::tuple<Tensor,Tensor,Tensor> dml_convolution_backward(const Tensor & grad_output, const Tensor & input, const Tensor & weight, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool transposed, IntArrayRef output_padding, int64_t groups, std::array<bool,3> output_mask);
TORCH_API Tensor & copy_(Tensor & self, const Tensor & src, bool non_blocking=false);
TORCH_API Tensor div(const Tensor & self, const Tensor & other);
TORCH_API Tensor & div_(Tensor & self, const Tensor & other);
TORCH_API Tensor & div_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & div_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor div(const Tensor & self, const Tensor & other, std::string rounding_mode);
TORCH_API Tensor & div_(Tensor & self, const Tensor & other, std::string rounding_mode);
TORCH_API Tensor & div_out(Tensor & out, const Tensor & self, const Tensor & other, std::string rounding_mode);
TORCH_API Tensor & div_outf(const Tensor & self, const Tensor & other, std::string rounding_mode, Tensor & out);
TORCH_API Tensor div(const Tensor & self, Scalar other);
TORCH_API Tensor & div_(Tensor & self, Scalar other);
TORCH_API Tensor empty(IntArrayRef size, TensorOptions options={}, c10::optional<MemoryFormat> memory_format=c10::nullopt);
TORCH_API Tensor empty(IntArrayRef size, c10::optional<ScalarType> dtype, c10::optional<Layout> layout, c10::optional<Device> device, c10::optional<bool> pin_memory, c10::optional<MemoryFormat> memory_format);
TORCH_API Tensor & resize_(Tensor & self, IntArrayRef size, c10::optional<MemoryFormat> memory_format=c10::nullopt);
TORCH_API Tensor empty_strided(IntArrayRef size, IntArrayRef stride, TensorOptions options={});
TORCH_API Tensor empty_strided(IntArrayRef size, IntArrayRef stride, c10::optional<ScalarType> dtype, c10::optional<Layout> layout, c10::optional<Device> device, c10::optional<bool> pin_memory);
TORCH_API Tensor exp(const Tensor & self);
TORCH_API Tensor & exp_(Tensor & self);
TORCH_API Tensor & exp_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & exp_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor & fill_(Tensor & self, Scalar value);
TORCH_API Tensor floor(const Tensor & self);
TORCH_API Tensor & floor_(Tensor & self);
TORCH_API Tensor & floor_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & floor_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor index(const Tensor & self, const c10::List<c10::optional<Tensor>> & indices);
TORCH_API Tensor & _index_put_impl_(Tensor & self, const c10::List<c10::optional<Tensor>> & indices, const Tensor & values, bool accumulate=false, bool unsafe=false);
TORCH_API Tensor log(const Tensor & self);
TORCH_API Tensor & log_(Tensor & self);
TORCH_API Tensor & log_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & log_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor log10(const Tensor & self);
TORCH_API Tensor & log10_(Tensor & self);
TORCH_API Tensor & log10_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & log10_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor log1p(const Tensor & self);
TORCH_API Tensor & log1p_(Tensor & self);
TORCH_API Tensor & log1p_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & log1p_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor log2(const Tensor & self);
TORCH_API Tensor & log2_(Tensor & self);
TORCH_API Tensor & log2_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & log2_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor _log_softmax(const Tensor & self, int64_t dim, bool half_to_float);
TORCH_API Tensor _log_softmax_backward_data(const Tensor & grad_output, const Tensor & output, int64_t dim, const Tensor & self);
TORCH_API std::tuple<Tensor,Tensor> max(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor mean(const Tensor & self, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor mean(const Tensor & self, IntArrayRef dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & mean_out(Tensor & out, const Tensor & self, IntArrayRef dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & mean_outf(const Tensor & self, IntArrayRef dim, bool keepdim, c10::optional<ScalarType> dtype, Tensor & out);
TORCH_API Tensor mm(const Tensor & self, const Tensor & mat2);
TORCH_API Tensor & mm_out(Tensor & out, const Tensor & self, const Tensor & mat2);
TORCH_API Tensor & mm_outf(const Tensor & self, const Tensor & mat2, Tensor & out);
TORCH_API Tensor mul(const Tensor & self, const Tensor & other);
TORCH_API Tensor & mul_(Tensor & self, const Tensor & other);
TORCH_API Tensor & mul_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & mul_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor mul(const Tensor & self, Scalar other);
TORCH_API Tensor & mul_(Tensor & self, Scalar other);
TORCH_API std::tuple<Tensor,Tensor,Tensor> native_batch_norm(const Tensor & input, const c10::optional<Tensor> & weight, const c10::optional<Tensor> & bias, const c10::optional<Tensor> & running_mean, const c10::optional<Tensor> & running_var, bool training, double momentum, double eps);
TORCH_API std::tuple<Tensor,Tensor,Tensor> native_batch_norm_backward(const Tensor & grad_out, const Tensor & input, const c10::optional<Tensor> & weight, const c10::optional<Tensor> & running_mean, const c10::optional<Tensor> & running_var, const c10::optional<Tensor> & save_mean, const c10::optional<Tensor> & save_invstd, bool train, double eps, std::array<bool,3> output_mask);
TORCH_API Tensor & randperm_out(Tensor & out, int64_t n, c10::optional<Generator> generator);
TORCH_API Tensor & randperm_outf(int64_t n, c10::optional<Generator> generator, Tensor & out);
TORCH_API Tensor reciprocal(const Tensor & self);
TORCH_API Tensor & reciprocal_(Tensor & self);
TORCH_API Tensor & reciprocal_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & reciprocal_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor & neg_(Tensor & self);
TORCH_API Tensor & neg_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & neg_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor repeat(const Tensor & self, IntArrayRef repeats);
TORCH_API Tensor round(const Tensor & self);
TORCH_API Tensor & round_(Tensor & self);
TORCH_API Tensor & round_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & round_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor relu(const Tensor & self);
TORCH_API Tensor & relu_(Tensor & self);
TORCH_API Tensor rsqrt(const Tensor & self);
TORCH_API Tensor & rsqrt_(Tensor & self);
TORCH_API Tensor & rsqrt_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & rsqrt_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor silu(const Tensor & self);
TORCH_API Tensor & silu_(Tensor & self);
TORCH_API Tensor & silu_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & silu_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor sigmoid(const Tensor & self);
TORCH_API Tensor & sigmoid_(Tensor & self);
TORCH_API Tensor & sigmoid_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & sigmoid_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor _softmax(const Tensor & self, int64_t dim, bool half_to_float);
TORCH_API std::vector<Tensor> split_with_sizes(const Tensor & self, IntArrayRef split_sizes, int64_t dim=0);
TORCH_API Tensor sum(const Tensor & self, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor sum(const Tensor & self, IntArrayRef dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & sum_out(Tensor & out, const Tensor & self, IntArrayRef dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & sum_outf(const Tensor & self, IntArrayRef dim, bool keepdim, c10::optional<ScalarType> dtype, Tensor & out);
TORCH_API Tensor sqrt(const Tensor & self);
TORCH_API Tensor & sqrt_(Tensor & self);
TORCH_API Tensor & sqrt_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & sqrt_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor prod(const Tensor & self, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor prod(const Tensor & self, int64_t dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & prod_out(Tensor & out, const Tensor & self, int64_t dim, bool keepdim=false, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & prod_outf(const Tensor & self, int64_t dim, bool keepdim, c10::optional<ScalarType> dtype, Tensor & out);
TORCH_API Tensor threshold(const Tensor & self, Scalar threshold, Scalar value);
TORCH_API Tensor & threshold_(Tensor & self, Scalar threshold, Scalar value);
TORCH_API Tensor & threshold_out(Tensor & out, const Tensor & self, Scalar threshold, Scalar value);
TORCH_API Tensor & threshold_outf(const Tensor & self, Scalar threshold, Scalar value, Tensor & out);
TORCH_API Tensor threshold_backward(const Tensor & grad_output, const Tensor & self, Scalar threshold);
TORCH_API Tensor flip(const Tensor & self, IntArrayRef dims);
TORCH_API std::tuple<Tensor,Tensor,Tensor> _unique2(const Tensor & self, bool sorted=true, bool return_inverse=false, bool return_counts=false);
TORCH_API Tensor _s_where(const Tensor & condition, const Tensor & self, const Tensor & other);
TORCH_API Tensor clone(const Tensor & self, c10::optional<MemoryFormat> memory_format=c10::nullopt);
TORCH_API Tensor & zero_(Tensor & self);
TORCH_API Tensor & sub_out(Tensor & out, const Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor & sub_outf(const Tensor & self, const Tensor & other, Scalar alpha, Tensor & out);
TORCH_API Tensor sub(const Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor & sub_(Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor rsub(const Tensor & self, const Tensor & other, Scalar alpha=1);
TORCH_API Tensor rsub(const Tensor & self, Scalar other, Scalar alpha=1);
TORCH_API Tensor & addmm_out(Tensor & out, const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta=1, Scalar alpha=1);
TORCH_API Tensor & addmm_outf(const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta, Scalar alpha, Tensor & out);
TORCH_API Tensor addmm(const Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta=1, Scalar alpha=1);
TORCH_API Tensor & addmm_(Tensor & self, const Tensor & mat1, const Tensor & mat2, Scalar beta=1, Scalar alpha=1);
TORCH_API Scalar _local_scalar_dense(const Tensor & self);
TORCH_API Tensor & masked_fill_(Tensor & self, const Tensor & mask, Scalar value);
TORCH_API Tensor & masked_fill_(Tensor & self, const Tensor & mask, const Tensor & value);
TORCH_API Tensor view(const Tensor & self, IntArrayRef size);
TORCH_API Tensor & scatter_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & src);
TORCH_API Tensor & eq_(Tensor & self, Scalar other);
TORCH_API Tensor & eq_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & eq_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor eq(const Tensor & self, Scalar other);
TORCH_API Tensor & eq_(Tensor & self, const Tensor & other);
TORCH_API Tensor & eq_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & eq_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor eq(const Tensor & self, const Tensor & other);
TORCH_API Tensor & bitwise_and_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & bitwise_and_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor & bitwise_and_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & bitwise_and_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor & bitwise_or_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & bitwise_or_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor & bitwise_or_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & bitwise_or_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor & remainder_(Tensor & self, Scalar other);
TORCH_API Tensor & remainder_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & remainder_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor remainder(const Tensor & self, Scalar other);
TORCH_API Tensor & remainder_(Tensor & self, const Tensor & other);
TORCH_API Tensor & remainder_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & remainder_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor remainder(const Tensor & self, const Tensor & other);
TORCH_API Tensor & addcdiv_out(Tensor & out, const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value=1);
TORCH_API Tensor & addcdiv_outf(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value, Tensor & out);
TORCH_API Tensor & random_(Tensor & self, int64_t from, c10::optional<int64_t> to, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & random_(Tensor & self, int64_t to, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & random_(Tensor & self, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & uniform_(Tensor & self, double from=0, double to=1, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor & ne_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & ne_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor ne(const Tensor & self, Scalar other);
TORCH_API Tensor & ne_(Tensor & self, Scalar other);
TORCH_API Tensor & ne_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & ne_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor ne(const Tensor & self, const Tensor & other);
TORCH_API Tensor & ne_(Tensor & self, const Tensor & other);
TORCH_API Tensor & ge_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & ge_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor ge(const Tensor & self, Scalar other);
TORCH_API Tensor & ge_(Tensor & self, Scalar other);
TORCH_API Tensor & ge_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & ge_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor ge(const Tensor & self, const Tensor & other);
TORCH_API Tensor & ge_(Tensor & self, const Tensor & other);
TORCH_API Tensor & le_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & le_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor le(const Tensor & self, Scalar other);
TORCH_API Tensor & le_(Tensor & self, Scalar other);
TORCH_API Tensor & le_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & le_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor le(const Tensor & self, const Tensor & other);
TORCH_API Tensor & le_(Tensor & self, const Tensor & other);
TORCH_API Tensor & gt_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & gt_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor gt(const Tensor & self, Scalar other);
TORCH_API Tensor & gt_(Tensor & self, Scalar other);
TORCH_API Tensor & gt_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & gt_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor gt(const Tensor & self, const Tensor & other);
TORCH_API Tensor & gt_(Tensor & self, const Tensor & other);
TORCH_API Tensor & lt_out(Tensor & out, const Tensor & self, Scalar other);
TORCH_API Tensor & lt_outf(const Tensor & self, Scalar other, Tensor & out);
TORCH_API Tensor lt(const Tensor & self, Scalar other);
TORCH_API Tensor & lt_(Tensor & self, Scalar other);
TORCH_API Tensor & lt_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & lt_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor lt(const Tensor & self, const Tensor & other);
TORCH_API Tensor & lt_(Tensor & self, const Tensor & other);
TORCH_API Tensor & index_select_out(Tensor & out, const Tensor & self, int64_t dim, const Tensor & index);
TORCH_API Tensor & index_select_outf(const Tensor & self, int64_t dim, const Tensor & index, Tensor & out);
TORCH_API Tensor index_select(const Tensor & self, int64_t dim, const Tensor & index);
TORCH_API Tensor & masked_select_out(Tensor & out, const Tensor & self, const Tensor & mask);
TORCH_API Tensor & masked_select_outf(const Tensor & self, const Tensor & mask, Tensor & out);
TORCH_API Tensor masked_select(const Tensor & self, const Tensor & mask);
TORCH_API Tensor & nonzero_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & nonzero_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor nonzero(const Tensor & self);
TORCH_API Tensor & addcmul_out(Tensor & out, const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value=1);
TORCH_API Tensor & addcmul_outf(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, Scalar value, Tensor & out);
TORCH_API Tensor sign(const Tensor & self);
TORCH_API Tensor & sign_(Tensor & self);
TORCH_API Tensor & sign_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & sign_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor min(const Tensor & self);
TORCH_API Tensor max(const Tensor & self);
TORCH_API Tensor maximum(const Tensor & self, const Tensor & other);
TORCH_API Tensor & maximum_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & maximum_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor minimum(const Tensor & self, const Tensor & other);
TORCH_API Tensor & minimum_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & minimum_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API std::tuple<Tensor,Tensor> sort(const Tensor & self, int64_t dim=-1, bool descending=false);
TORCH_API std::tuple<Tensor &,Tensor &> topk_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t k, int64_t dim=-1, bool largest=true, bool sorted=true);
TORCH_API std::tuple<Tensor &,Tensor &> topk_outf(const Tensor & self, int64_t k, int64_t dim, bool largest, bool sorted, Tensor & values, Tensor & indices);
TORCH_API std::tuple<Tensor,Tensor> topk(const Tensor & self, int64_t k, int64_t dim=-1, bool largest=true, bool sorted=true);
TORCH_API Tensor all(const Tensor & self);
TORCH_API Tensor any(const Tensor & self);
TORCH_API Tensor unfold(const Tensor & self, int64_t dimension, int64_t size, int64_t step);
TORCH_API Tensor & pow_out(Tensor & out, const Tensor & self, const Tensor & exponent);
TORCH_API Tensor & pow_outf(const Tensor & self, const Tensor & exponent, Tensor & out);
TORCH_API Tensor pow(const Tensor & self, const Tensor & exponent);
TORCH_API Tensor & pow_(Tensor & self, const Tensor & exponent);
TORCH_API Tensor & pow_out(Tensor & out, const Tensor & self, Scalar exponent);
TORCH_API Tensor & pow_outf(const Tensor & self, Scalar exponent, Tensor & out);
TORCH_API Tensor pow(const Tensor & self, Scalar exponent);
TORCH_API Tensor & pow_(Tensor & self, Scalar exponent);
TORCH_API Tensor alias(const Tensor & self);
TORCH_API Tensor _cat(TensorList tensors, int64_t dim=0);
TORCH_API Tensor & l1_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction);
TORCH_API Tensor & l1_loss_backward_outf(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction, Tensor & grad_input);
TORCH_API std::tuple<Tensor,Tensor> nll_loss_forward(const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight, int64_t reduction, int64_t ignore_index);
TORCH_API Tensor & nll_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight, int64_t reduction, int64_t ignore_index, const Tensor & total_weight);
TORCH_API Tensor & nll_loss_backward_outf(const Tensor & grad_output, const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight, int64_t reduction, int64_t ignore_index, const Tensor & total_weight, Tensor & grad_input);
TORCH_API Tensor nll_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight, int64_t reduction, int64_t ignore_index, const Tensor & total_weight);
TORCH_API Tensor & hardsigmoid_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & hardsigmoid_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor hardsigmoid(const Tensor & self);
TORCH_API Tensor & hardsigmoid_(Tensor & self);
TORCH_API Tensor hardsigmoid_backward(const Tensor & grad_output, const Tensor & self);
TORCH_API Tensor & hardtanh_out(Tensor & out, const Tensor & self, Scalar min_val=-1, Scalar max_val=1);
TORCH_API Tensor & hardtanh_outf(const Tensor & self, Scalar min_val, Scalar max_val, Tensor & out);
TORCH_API Tensor hardtanh(const Tensor & self, Scalar min_val=-1, Scalar max_val=1);
TORCH_API Tensor & hardtanh_(Tensor & self, Scalar min_val=-1, Scalar max_val=1);
TORCH_API Tensor & hardtanh_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, Scalar min_val, Scalar max_val);
TORCH_API Tensor & hardtanh_backward_outf(const Tensor & grad_output, const Tensor & self, Scalar min_val, Scalar max_val, Tensor & grad_input);
TORCH_API Tensor hardtanh_backward(const Tensor & grad_output, const Tensor & self, Scalar min_val, Scalar max_val);
TORCH_API Tensor & hardswish_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & hardswish_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor hardswish(const Tensor & self);
TORCH_API Tensor & hardswish_(Tensor & self);
TORCH_API Tensor hardswish_backward(const Tensor & grad_output, const Tensor & self);
TORCH_API Tensor & leaky_relu_out(Tensor & out, const Tensor & self, Scalar negative_slope=0.01);
TORCH_API Tensor & leaky_relu_outf(const Tensor & self, Scalar negative_slope, Tensor & out);
TORCH_API Tensor leaky_relu(const Tensor & self, Scalar negative_slope=0.01);
TORCH_API Tensor & leaky_relu_(Tensor & self, Scalar negative_slope=0.01);
TORCH_API Tensor leaky_relu_backward(const Tensor & grad_output, const Tensor & self, Scalar negative_slope, bool self_is_result);
TORCH_API Tensor _adaptive_avg_pool2d(const Tensor & self, IntArrayRef output_size);
TORCH_API Tensor _adaptive_avg_pool2d_backward(const Tensor & grad_output, const Tensor & self);
TORCH_API Tensor & avg_pool2d_out(Tensor & out, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride={}, IntArrayRef padding=0, bool ceil_mode=false, bool count_include_pad=true, c10::optional<int64_t> divisor_override=c10::nullopt);
TORCH_API Tensor & avg_pool2d_outf(const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override, Tensor & out);
TORCH_API Tensor avg_pool2d(const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride={}, IntArrayRef padding=0, bool ceil_mode=false, bool count_include_pad=true, c10::optional<int64_t> divisor_override=c10::nullopt);
TORCH_API Tensor & avg_pool2d_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
TORCH_API Tensor & avg_pool2d_backward_outf(const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override, Tensor & grad_input);
TORCH_API Tensor avg_pool2d_backward(const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, bool ceil_mode, bool count_include_pad, c10::optional<int64_t> divisor_override);
TORCH_API std::tuple<Tensor &,Tensor &> max_pool2d_with_indices_out(Tensor & out, Tensor & indices, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride={}, IntArrayRef padding=0, IntArrayRef dilation=1, bool ceil_mode=false);
TORCH_API std::tuple<Tensor &,Tensor &> max_pool2d_with_indices_outf(const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool ceil_mode, Tensor & out, Tensor & indices);
TORCH_API std::tuple<Tensor,Tensor> max_pool2d_with_indices(const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride={}, IntArrayRef padding=0, IntArrayRef dilation=1, bool ceil_mode=false);
TORCH_API Tensor & max_pool2d_with_indices_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool ceil_mode, const Tensor & indices);
TORCH_API Tensor & max_pool2d_with_indices_backward_outf(const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool ceil_mode, const Tensor & indices, Tensor & grad_input);
TORCH_API Tensor max_pool2d_with_indices_backward(const Tensor & grad_output, const Tensor & self, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool ceil_mode, const Tensor & indices);
TORCH_API Tensor upsample_bilinear2d(const Tensor & input, c10::optional<IntArrayRef> output_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_bilinear2d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor & upsample_bilinear2d_out(Tensor & out, const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_bilinear2d_outf(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w, Tensor & out);
TORCH_API Tensor upsample_bilinear2d(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_bilinear2d_backward_out(Tensor & grad_input, const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_bilinear2d_backward_outf(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_h, c10::optional<double> scales_w, Tensor & grad_input);
TORCH_API Tensor upsample_bilinear2d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_nearest2d_out(Tensor & out, const Tensor & self, IntArrayRef output_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_nearest2d_outf(const Tensor & self, IntArrayRef output_size, c10::optional<double> scales_h, c10::optional<double> scales_w, Tensor & out);
TORCH_API Tensor upsample_nearest2d(const Tensor & self, IntArrayRef output_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_nearest2d_backward_out(Tensor & grad_input, const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & upsample_nearest2d_backward_outf(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales_h, c10::optional<double> scales_w, Tensor & grad_input);
TORCH_API Tensor upsample_nearest2d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor & sigmoid_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & output);
TORCH_API Tensor & sigmoid_backward_outf(const Tensor & grad_output, const Tensor & output, Tensor & grad_input);
TORCH_API Tensor sigmoid_backward(const Tensor & grad_output, const Tensor & output);
TORCH_API std::tuple<Tensor &,Tensor &,Tensor &> thnn_conv2d_forward_out(Tensor & output, Tensor & finput, Tensor & fgrad_input, const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, const c10::optional<Tensor> & bias, IntArrayRef stride, IntArrayRef padding);
TORCH_API std::tuple<Tensor &,Tensor &,Tensor &> thnn_conv2d_forward_outf(const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, const c10::optional<Tensor> & bias, IntArrayRef stride, IntArrayRef padding, Tensor & output, Tensor & finput, Tensor & fgrad_input);
TORCH_API std::tuple<Tensor,Tensor,Tensor> thnn_conv2d_forward(const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, const c10::optional<Tensor> & bias, IntArrayRef stride, IntArrayRef padding);
TORCH_API std::tuple<Tensor &,Tensor &,Tensor &> thnn_conv2d_backward_out(Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias, const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, const Tensor & finput, const Tensor & fgrad_input);
TORCH_API std::tuple<Tensor &,Tensor &,Tensor &> thnn_conv2d_backward_outf(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, const Tensor & finput, const Tensor & fgrad_input, Tensor & grad_input, Tensor & grad_weight, Tensor & grad_bias);
TORCH_API std::tuple<Tensor,Tensor,Tensor> thnn_conv2d_backward(const Tensor & grad_output, const Tensor & self, const Tensor & weight, IntArrayRef kernel_size, IntArrayRef stride, IntArrayRef padding, const Tensor & finput, const Tensor & fgrad_input, std::array<bool,3> output_mask);

} // namespace dml
} // namespace at
